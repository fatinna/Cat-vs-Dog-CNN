{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cat vs Dog CNN Classification using TensorFlow/Keras"
      ],
      "metadata": {
        "id": "mAX8iy2VUR0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "metadata": {
        "id": "9Y3agA9AVpxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Download and extract the dataset**\n",
        "\n",
        "Download the 'Dogs vs Cats' dataset manually from Kaggle or use the Kaggle API.\n",
        "\n",
        "If you're using the Kaggle API, upload your `kaggle.json` file and run the following commands:\n",
        "\n",
        "```python\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!kaggle datasets download -d salader/dogs-vs-cats\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')\n"
      ],
      "metadata": {
        "id": "NcM1A1ovWKyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Load datasets ---\n",
        "\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/train',  # Change path to your train folder\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size=32,\n",
        "    image_size=(256, 256)\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/test',  # Change path to your test/validation folder\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size=32,\n",
        "    image_size=(256, 256)\n",
        ")"
      ],
      "metadata": {
        "id": "mXQRJJU7Wra-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Normalize images ---\n",
        "\n",
        "def normalize(image, label):\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(normalize)\n",
        "validation_ds = validation_ds.map(normalize)"
      ],
      "metadata": {
        "id": "dUhumyBJW_c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## --- Step 4: Build CNN model ---\n",
        "# 3 convolutional layer\n",
        "# first layer has 32 filters, 2nd layer has 64 filters and 3rd layer has 128 filters\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(64,64,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(64,64,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(64,64,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "#Fully connected layer\n",
        "# 3 layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "r295PfpFXDFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_dN_UodVXDIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Train the model ---\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=25,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
        ")\n"
      ],
      "metadata": {
        "id": "eyjOTWwBXDLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Direct Evaluation (no model loading needed)\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"\\nTest Accuracy: {test_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "TRp5LTZSXDPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Plot training results ---\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue', linewidth=2) # Changed cnn_history to historty\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red', linewidth=2) # Changed cnn_history to historty\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue', linewidth=2)\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red', linewidth=2)\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z8zn-TKkX6uP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 for cat and 1 for dog"
      ],
      "metadata": {
        "id": "inmeeK0eYzSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7: Predict on a new image ---\n",
        "# Load and preprocess an example image (change the path accordingly)\n",
        "test_img_path = '/content/dog.jpg'\n",
        "test_img = cv2.imread(test_img_path)\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for plt.imshow\n",
        "test_img_resized = cv2.resize(test_img, (256, 256))\n",
        "test_input = test_img_resized.reshape((1, 256, 256, 3)) / 255.0  # Normalize input\n",
        "\n",
        "plt.imshow(test_img_resized)\n",
        "plt.title('Test Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(test_input)\n",
        "\n",
        "# Classify result\n",
        "if prediction[0][0] >= 0.5:\n",
        "    print(f\"Prediction: Dog ({prediction[0][0]:.4f})\")\n",
        "else:\n",
        "    print(f\"Prediction: Cat ({prediction[0][0]:.4f})\")\n"
      ],
      "metadata": {
        "id": "H6jPXbZmX6wk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}